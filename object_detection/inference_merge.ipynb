{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nW4BN-FEHAn"
   },
   "source": [
    "# STEP 0: Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u3rG-rjUEKyZ",
    "outputId": "ec3d06cd-52a5-4350-cceb-462a736acbc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure you use the Colab GPU to run the testing phase\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4M1nNaTRgQm",
    "outputId": "09d162b4-f6ea-4768-bac4-f9e6df2f0b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu102 True\n"
     ]
    }
   ],
   "source": [
    "# Import your package and check the version\n",
    "\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "\n",
    "# You must import the below 5 packages \n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from utils.torch_utils import select_device, time_sync\n",
    "from utils.general import check_file, check_img_size, check_imshow, non_max_suppression, scale_coords, xyxy2xywh\n",
    "from utils.datasets import LoadImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTs4phq2W8zG",
    "outputId": "c001ab7e-08ee-4405-decb-987b7ef2329a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 25f814d torch 1.9.0+cu102 CUDA:0 (NVIDIA TITAN RTX, 24220MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86220517 parameters, 0 gradients\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "device = ''\n",
    "device = select_device(device)\n",
    "model = DetectMultiBackend(\"./runs/train/fish_yolov5x_pre_640_G075/weights/best.pt\", device=device, dnn=False)\n",
    "stride, names, pt, jit, onnx = model.stride, model.names, model.pt, model.jit, model.onnx\n",
    "if pt and device.type != 'cpu':\n",
    "    model(torch.zeros(1, 3, 640, 480).to(device).type_as(next(model.model.parameters())))  # warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "classification_model_path = \"../checkpoint/swin_crop/checkpoint.pth.tar\"\n",
    "model_classification = torch.load(classification_model_path).eval().to(device)\n",
    "smax = nn.Softmax(dim=1)\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")\n",
    "\n",
    "def classification(img):\n",
    "    with torch.no_grad():\n",
    "        img = transform(img)\n",
    "        avg_B = torch.mean(img[0])\n",
    "        avg_G = torch.mean(img[1])\n",
    "        avg_R = torch.mean(img[2])\n",
    "        if (avg_G - 0.05 > avg_B and avg_G - 0.05 > avg_R):\n",
    "            img[1] = img[1] * 0.75\n",
    "        data = img.unsqueeze(0).to(device)\n",
    "        output = model_classification(data)\n",
    "        output = smax(output).detach().cpu().numpy()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVr_Mls8NBe6",
    "outputId": "094b9b68-e14b-4ffa-ffe6-2fcc87989284"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [01:27<00:00, 11.47it/s]\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 6323/12153 [07:16<07:16, 13.35it/s]"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "# Use the results from your model to generate the output json file\n",
    "data_path_stg1 = \"../../../DATA/fish/test_stg1/\"\n",
    "data_path_stg2 = \"../../../DATA/fish/test_stg2/\"\n",
    "test_path = [\"../../../DATA/fish/train/DOL/\", \"../../../DATA/fish/train/YFT/\", \"../../../DATA/fish/train/NoF/\"]\n",
    "dataset_stg1 = LoadImages(data_path_stg1, img_size=(640,480), stride=stride, auto=pt and not jit)\n",
    "dataset_stg2 = LoadImages(data_path_stg2, img_size=(640,480), stride=stride, auto=pt and not jit)\n",
    "\n",
    "conf_thres=0.25\n",
    "iou_thres=0.45\n",
    "max_det=100\n",
    "agnostic_nms=False\n",
    "classes=None\n",
    "# Blue color in BGR\n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "\n",
    "\n",
    "copy_path_stg1 = \"../../../DATA/fish/ToSwin/test_stg1/\"\n",
    "copy_path_stg2 = \"../../../DATA/fish/ToSwin/test_stg2/\"\n",
    "\n",
    "def copyNoFishImg(image_path, stg):\n",
    "    src = \"\"\n",
    "    output = \"\"\n",
    "    if stg == 1:\n",
    "        src = data_path_stg1 + image_path\n",
    "        output = copy_path_stg1 + image_path\n",
    "    else:\n",
    "        src = data_path_stg2 + image_path\n",
    "        output = copy_path_stg2 + image_path\n",
    "    img = cv2.imread(src)\n",
    "    cv2.imwrite(output, img)\n",
    "\n",
    "\n",
    "# for each test image\n",
    "def inference_to_csv(dataset, writer, stg):\n",
    "    for img_path, img, im0s, vid_cap, s in tqdm(dataset):\n",
    "    # for img_name in data_listdir:\n",
    "        # the image_name is as same as the image_id\n",
    "        img_name = os.path.basename(img_path)\n",
    "        if (stg == 2):\n",
    "            image_id = int(img_name[6:-4])\n",
    "        elif (stg == 1):\n",
    "            image_id = int(img_name[4:-4])\n",
    "        # add each detection box infomation into list\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.float()  # uint8 to fp16/32\n",
    "        img /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        avg_B = torch.mean(img[0])\n",
    "        avg_G = torch.mean(img[1])\n",
    "        avg_R = torch.mean(img[2])\n",
    "        if (avg_G - 0.05 > avg_B and avg_G - 0.05 > avg_R):\n",
    "            img[1] = img[1] * 0.75\n",
    "        if len(img.shape) == 3:\n",
    "            img = img[None]  # expand for batch dim\n",
    "        pred = model(img)\n",
    "        pred_max = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "        det = pred_max[0]\n",
    "        pred = pred_max\n",
    "        gn = torch.tensor(im0s.shape)[[1, 0, 1, 0]]\n",
    "        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0s.shape).round()\n",
    "        \n",
    "        pre_value = [0,0,0,0,0,0,0,0]\n",
    "        # for det_box in all_det_boxes_in_this_image:\n",
    "#         for *xyxy, conf, cls in reversed(det):\n",
    "#             pre_value[int(cls.cpu().numpy())] = max(float(conf.cpu().numpy()), pre_value[int(cls.cpu().numpy())])\n",
    "#             pre_value[4] = 1. - pre_value[int(cls.cpu().numpy())]\n",
    "        for *xyxy, conf, cls in reversed(det):\n",
    "            xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "            w = int(xywh[2] * im0s.shape[1])\n",
    "            h = int(xywh[3]* im0s.shape[0])\n",
    "            x = int((xywh[0] * im0s.shape[1]) - (w/2))\n",
    "            y = int((xywh[1] * im0s.shape[0]) - (h/2))\n",
    "            crop_img = im0s[y:y+h, x:x+w]\n",
    "            classification_pre = classification(crop_img)[0]\n",
    "            pre_value[0] = max(float(classification_pre[0]), pre_value[0])\n",
    "            pre_value[1] = max(float(classification_pre[1]), pre_value[1])\n",
    "            pre_value[2] = max(float(classification_pre[2]), pre_value[2])\n",
    "            pre_value[3] = max(float(classification_pre[3]), pre_value[3])\n",
    "            pre_value[5] = max(float(classification_pre[4]), pre_value[5])\n",
    "            pre_value[6] = max(float(classification_pre[5]), pre_value[6])\n",
    "            pre_value[7] = max(float(classification_pre[6]), pre_value[7])\n",
    "        for i in range(len(pre_value)):\n",
    "            if i == 1 or i == 7:\n",
    "                pre_value[i]+=0.05\n",
    "            else:\n",
    "                pre_value[i]+=0.01\n",
    "        if (len(det) == 0):\n",
    "#             copyNoFishImg(img_name, stg)\n",
    "#             continue\n",
    "            pre_value[4] = float(1)\n",
    "        if (stg == 2):\n",
    "            img_name = \"test_stg2/\" + img_name\n",
    "        row = [img_name] + pre_value\n",
    "        writer.writerow(row)\n",
    "   \n",
    "\n",
    "with open(\"answer.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"image\", \"ALB\", \"BET\", \"DOL\", \"LAG\", \"NoF\", \"OTHER\", \"SHARK\", \"YFT\"])\n",
    "    inference_to_csv(dataset_stg1, writer, 1)\n",
    "    inference_to_csv(dataset_stg2, writer, 2)\n",
    "#     for p in test_path:\n",
    "#         dataset_p = LoadImages(p, img_size=(640,480), stride=stride, auto=pt and not jit)\n",
    "#         inference_to_csv(dataset_p, writer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
